{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kc4WxYmLSBW5"
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --user google-cloud-aiplatform pymupdf rich colorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XRvKdaPDTznN"
   },
   "outputs": [],
   "source": [
    "# Restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbmM4z7FOBpM"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GpYEyLsOh2rL"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Additional authentication is required for Google Colab\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # Authenticate user to Google Cloud\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gJqZ76rJh2rM"
   },
   "outputs": [],
   "source": [
    "# Define project information\n",
    "\n",
    "import sys\n",
    "\n",
    "PROJECT_ID = \"YOUR_PROJECT_ID\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "# if not running on Colab, try to get the PROJECT_ID automatically\n",
    "if \"google.colab\" not in sys.modules:\n",
    "    import subprocess\n",
    "\n",
    "    PROJECT_ID = subprocess.check_output(\n",
    "        [\"gcloud\", \"config\", \"get-value\", \"project\"], text=True\n",
    "    ).strip()\n",
    "\n",
    "print(f\"Your project ID is: {PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D48gUW5-h2rM"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Initialize Vertex AI\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rtMowvm-yQ97"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "from rich.markdown import Markdown as rich_Markdown\n",
    "from vertexai.generative_models import GenerationConfig, GenerativeModel, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SvMwSRJJh2rM"
   },
   "outputs": [],
   "source": [
    "text_model = GenerativeModel(\"gemini-1.5-pro\")\n",
    "multimodal_model = GenerativeModel(\"gemini-1.5-pro\")\n",
    "multimodal_model_flash = GenerativeModel(\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KwbL89zcY39N"
   },
   "outputs": [],
   "source": [
    "# download documents and images used in this notebook\n",
    "!gsutil -m rsync -r gs://github-repo/rag/intro_multimodal_rag/intro_multimodal_rag_old_version .\n",
    "print(\"Download completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N3wo2jv2rP7v"
   },
   "outputs": [],
   "source": [
    "from intro_multimodal_rag_utils import get_document_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nflT_j-9QzC_"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ Do not send more than 50 pages in the logic below, its not degined to do that and you will get into quota issue. ⚠️</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X8hE0tWD-lf8"
   },
   "outputs": [],
   "source": [
    "# Specify the PDF folder with multiple PDF\n",
    "\n",
    "# pdf_folder_path = \"/content/data/\" # if running in Google Colab/Colab Enterprise\n",
    "pdf_folder_path = \"data/\"  # if running in Vertex AI Workbench.\n",
    "\n",
    "# Specify the image description prompt. Change it\n",
    "image_description_prompt = \"\"\"Explain what is going on in the image.\n",
    "If it's a table, extract all elements of the table.\n",
    "If it's a graph, explain the findings in the graph.\n",
    "Do not include any numbers that are not mentioned in the image.\n",
    "\"\"\"\n",
    "\n",
    "# Extract text and image metadata from the PDF document\n",
    "text_metadata_df, image_metadata_df = get_document_metadata(\n",
    "    multimodal_model,  # we are passing Gemini 1.5 Pro model\n",
    "    pdf_folder_path,\n",
    "    image_save_dir=\"images\",\n",
    "    image_description_prompt=image_description_prompt,\n",
    "    embedding_size=1408,\n",
    "    # add_sleep_after_page = True, # Uncomment this if you are running into API quota issues\n",
    "    # sleep_time_after_page = 5,\n",
    "    # generation_config = # see next cell\n",
    "    # safety_settings =  # see next cell\n",
    ")\n",
    "\n",
    "print(\"\\n\\n --- Completed processing. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQzMm5bNrP7w"
   },
   "outputs": [],
   "source": [
    "# # Parameters for Gemini API call.\n",
    "# # reference for parameters: https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini\n",
    "\n",
    "# generation_config=  GenerationConfig(temperature=0.2, max_output_tokens=2048)\n",
    "\n",
    "# # Set the safety settings if Gemini is blocking your content or you are facing \"ValueError(\"Content has no parts\")\" error or \"Exception occurred\" in your data.\n",
    "# # ref for settings and thresholds: https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/configure-safety-attributes\n",
    "\n",
    "# safety_settings = {\n",
    "#                   HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "#                   HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "#                   HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "#                   HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "#                   }\n",
    "\n",
    "# # You can also pass parameters and safety_setting to \"get_gemini_response\" function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "miBBoEXwh2rN"
   },
   "source": [
    "#### Inspect the processed text metadata\n",
    "\n",
    "\n",
    "The following cell will produce a metadata table which describes the different parts of text metadata, including:\n",
    "\n",
    "- **text**: the original text from the page\n",
    "- **text_embedding_page**: the embedding of the original text from the page\n",
    "- **chunk_text**: the original text divided into smaller chunks\n",
    "- **chunk_number**: the index of each text chunk\n",
    "- **text_embedding_chunk**: the embedding of each text chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6t3AIGFar8Mo"
   },
   "outputs": [],
   "source": [
    "text_metadata_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NjIQYI3mh2rO"
   },
   "source": [
    "#### Inspect the processed image metadata\n",
    "\n",
    "The following cell will produce a metadata table which describes the different parts of image metadata, including:\n",
    "* **img_desc**: Gemini-generated textual description of the image.\n",
    "* **mm_embedding_from_text_desc_and_img**: Combined embedding of image and its description, capturing both visual and textual information.\n",
    "* **mm_embedding_from_img_only**: Image embedding without description, for comparison with description-based analysis.\n",
    "* **text_embedding_from_image_description**: Separate text embedding of the generated description, enabling textual analysis and comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tkHtAYIK-y-q"
   },
   "outputs": [],
   "source": [
    "image_metadata_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBhoOkutUtPr"
   },
   "source": [
    "### Import the helper functions to implement RAG\n",
    "\n",
    "You will be importing the following functions which will be used in the remainder of this notebook to implement RAG:\n",
    "\n",
    "* **get_similar_text_from_query():** Given a text query, finds text from the document which are relevant, using cosine similarity algorithm. It uses text embeddings from the metadata to compute and the results can be filtered by top score, page/chunk number, or embedding size.\n",
    "* **print_text_to_text_citation():** Prints the source (citation) and details of the retrieved text from the `get_similar_text_from_query()` function.\n",
    "* **get_similar_image_from_query():** Given an image path or an image, finds images from the document which are relevant. It uses image embeddings from the metadata.\n",
    "* **print_text_to_image_citation():** Prints the source (citation) and the details of retrieved images from the `get_similar_image_from_query()` function.\n",
    "* **get_gemini_response():** Interacts with a Gemini model to answer questions based on a combination of text and image inputs.\n",
    "* **display_images():**  Displays a series of images provided as paths or PIL Image objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tngn_vrIKdE1"
   },
   "outputs": [],
   "source": [
    "from intro_multimodal_rag_utils import (\n",
    "    display_images,\n",
    "    get_gemini_response,\n",
    "    get_similar_image_from_query,\n",
    "    get_similar_text_from_query,\n",
    "    print_text_to_image_citation,\n",
    "    print_text_to_text_citation,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9jGEj6DY1Rj"
   },
   "source": [
    "Before implementing a multimodal RAG, let's take a step back and explore what you can achieve with just text or image embeddings alone. It will help to set the foundation for implementing a multimodal RAG, which you will be doing in the later part of the notebook. You can also use these essential elements together to build applications for multimodal use cases for extracting meaningful information from the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHuLlEvSKFWt"
   },
   "source": [
    "## Text Search\n",
    "\n",
    "Let's start the search with a simple question and see if the simple text search using text embeddings can answer it. The expected answer is to show the value of basic and diluted net income per share of Google for different share types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5mrFVhtCut7t"
   },
   "outputs": [],
   "source": [
    "query = \"I need details for basic and diluted net income per share of Class A, Class B, and Class C share for google?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWw7-AIar-S8"
   },
   "source": [
    "### Search similar text with text query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eEzP6Yyv7N-G"
   },
   "outputs": [],
   "source": [
    "# Matching user text query with \"chunk_embedding\" to find relevant chunks.\n",
    "matching_results_text = get_similar_text_from_query(\n",
    "    query,\n",
    "    text_metadata_df,\n",
    "    column_name=\"text_embedding_chunk\",\n",
    "    top_n=3,\n",
    "    chunk_text=True,\n",
    ")\n",
    "\n",
    "# Print the matched text citations\n",
    "print_text_to_text_citation(matching_results_text, print_top=False, chunk_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ORCistIdDWoE"
   },
   "outputs": [],
   "source": [
    "print(\"\\n **** Result: ***** \\n\")\n",
    "\n",
    "# All relevant text chunk found across documents based on user query\n",
    "context = \"\\n\".join(\n",
    "    [value[\"chunk_text\"] for key, value in matching_results_text.items()]\n",
    ")\n",
    "\n",
    "instruction = f\"\"\"Answer the question with the given context.\n",
    "If the information is not available in the context, just return \"not available in the context\".\n",
    "Question: {query}\n",
    "Context: {context}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Prepare the model input\n",
    "model_input = instruction\n",
    "\n",
    "# Generate Gemini response with streaming output\n",
    "get_gemini_response(\n",
    "    text_model,  # we are passing Gemini 1.0 Pro\n",
    "    model_input=model_input,\n",
    "    stream=True,\n",
    "    generation_config=GenerationConfig(temperature=0.2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0sRFH6tJlpXQ"
   },
   "outputs": [],
   "source": [
    "query = \"I need details for basic and diluted net income per share of Class A, Class B, and Class C share for google?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "knj4qQ4xni24"
   },
   "outputs": [],
   "source": [
    "matching_results_image = get_similar_image_from_query(\n",
    "    text_metadata_df,\n",
    "    image_metadata_df,\n",
    "    query=query,\n",
    "    column_name=\"text_embedding_from_image_description\",  # Use image description text embedding\n",
    "    image_emb=False,  # Use text embedding instead of image embedding\n",
    "    top_n=3,\n",
    "    embedding_size=1408,\n",
    ")\n",
    "\n",
    "# Markdown(print_text_to_image_citation(matching_results_image, print_top=True))\n",
    "print(\"\\n **** Result: ***** \\n\")\n",
    "\n",
    "# Display the top matching image\n",
    "display(matching_results_image[0][\"image_object\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ax6ooI0rP70"
   },
   "outputs": [],
   "source": [
    "print(\"\\n **** Result: ***** \\n\")\n",
    "\n",
    "# All relevant text chunk found across documents based on user query\n",
    "context = f\"\"\"Image: {matching_results_image[0]['image_object']}\n",
    "Description: {matching_results_image[0]['image_description']}\n",
    "\"\"\"\n",
    "\n",
    "instruction = f\"\"\"Answer the question in JSON format with the given context of Image and its Description. Only include value.\n",
    "Question: {query}\n",
    "Context: {context}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Prepare the model input\n",
    "model_input = instruction\n",
    "\n",
    "# Generate Gemini response with streaming output\n",
    "Markdown(\n",
    "    get_gemini_response(\n",
    "        multimodal_model_flash,  # we are passing Gemini 1.5 Pro Flash\n",
    "        model_input=model_input,\n",
    "        stream=True,\n",
    "        generation_config=GenerationConfig(temperature=1),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eAxSk640rP70"
   },
   "outputs": [],
   "source": [
    "## you can check the citations to probe further.\n",
    "## check the \"image description:\" which is a description extracted through Gemini which helped search our query.\n",
    "Markdown(print_text_to_image_citation(matching_results_image, print_top=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DJhhS5eZw7QI"
   },
   "outputs": [],
   "source": [
    "# You can find a similar image as per the images you have in the metadata.\n",
    "# In this case, you have a table (picked from the same document source) and you would like to find similar tables in the document.\n",
    "image_query_path = \"tac_table_revenue.png\"\n",
    "\n",
    "# Print a message indicating the input image\n",
    "print(\"***Input image from user:***\")\n",
    "\n",
    "# Display the input image\n",
    "Image.load_from_file(image_query_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZcU7vZC-8vr"
   },
   "outputs": [],
   "source": [
    "# Search for Similar Images Based on Input Image and Image Embedding\n",
    "\n",
    "matching_results_image = get_similar_image_from_query(\n",
    "    text_metadata_df,\n",
    "    image_metadata_df,\n",
    "    query=query,  # Use query text for additional filtering (optional)\n",
    "    column_name=\"mm_embedding_from_img_only\",  # Use image embedding for similarity calculation\n",
    "    image_emb=True,\n",
    "    image_query_path=image_query_path,  # Use input image for similarity calculation\n",
    "    top_n=3,  # Retrieve top 3 matching images\n",
    "    embedding_size=1408,  # Use embedding size of 1408\n",
    ")\n",
    "\n",
    "print(\"\\n **** Result: ***** \\n\")\n",
    "\n",
    "# Display the Top Matching Image\n",
    "display(\n",
    "    matching_results_image[0][\"image_object\"]\n",
    ")  # Display the top matching image object (Pillow Image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mksXQoezweg0"
   },
   "outputs": [],
   "source": [
    "# Display citation details for the top matching image\n",
    "print_text_to_image_citation(\n",
    "    matching_results_image, print_top=True\n",
    ")  # Print citation details for the top matching image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VJWnhDJwI-uO"
   },
   "outputs": [],
   "source": [
    "# Check Other Matched Images (Optional)\n",
    "# You can access the other two matched images using:\n",
    "\n",
    "print(\"---------------Matched Images------------------\\n\")\n",
    "display_images(\n",
    "    [\n",
    "        matching_results_image[0][\"img_path\"],\n",
    "        matching_results_image[1][\"img_path\"],\n",
    "    ],\n",
    "    resize_ratio=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E6AHCSwojyX0"
   },
   "outputs": [],
   "source": [
    "matching_results_image_query_1 = get_similar_image_from_query(\n",
    "    text_metadata_df,\n",
    "    image_metadata_df,\n",
    "    query=\"Show me all the graphs that shows Google Class A cumulative 5-year total return\",\n",
    "    column_name=\"text_embedding_from_image_description\",  # Use image description text embedding # mm_embedding_from_img_only text_embedding_from_image_description\n",
    "    image_emb=False,  # Use text embedding instead of image embedding\n",
    "    top_n=3,\n",
    "    embedding_size=1408,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3FRXk-n0rP71"
   },
   "outputs": [],
   "source": [
    "# Check Matched Images\n",
    "# You can access the other two matched images using:\n",
    "\n",
    "print(\"---------------Matched Images------------------\\n\")\n",
    "display_images(\n",
    "    [\n",
    "        matching_results_image_query_1[0][\"img_path\"],\n",
    "        matching_results_image_query_1[1][\"img_path\"],\n",
    "    ],\n",
    "    resize_ratio=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fSR_JWkSC_7p"
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\" Instructions: Compare the images and the Gemini extracted text provided as Context: to answer Question:\n",
    "Make sure to think thoroughly before answering the question and put the necessary steps to arrive at the answer in bullet points for easy explainability.\n",
    "\n",
    "Context:\n",
    "Image_1: {matching_results_image_query_1[0][\"image_object\"]}\n",
    "gemini_extracted_text_1: {matching_results_image_query_1[0]['image_description']}\n",
    "Image_2: {matching_results_image_query_1[1][\"image_object\"]}\n",
    "gemini_extracted_text_2: {matching_results_image_query_1[2]['image_description']}\n",
    "\n",
    "Question:\n",
    " - Key findings of Class A share?\n",
    " - What are the critical differences between the graphs for Class A Share?\n",
    " - What are the key findings of Class A shares concerning the S&P 500?\n",
    " - Which index best matches Class A share performance closely where Google is not already a part? Explain the reasoning.\n",
    " - Identify key chart patterns in both graphs.\n",
    " - Which index best matches Class A share performance closely where Google is not already a part? Explain the reasoning.\n",
    "\"\"\"\n",
    "\n",
    "# Generate Gemini response with streaming output\n",
    "rich_Markdown(\n",
    "    get_gemini_response(\n",
    "        multimodal_model,  # we are passing Gemini 1.5 Pro\n",
    "        model_input=[prompt],\n",
    "        stream=True,\n",
    "        generation_config=GenerationConfig(temperature=1),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XvTKFwOPHLQ_"
   },
   "outputs": [],
   "source": [
    "# this time we are not passing any images, but just a simple text query.\n",
    "\n",
    "query = \"\"\"Questions:\n",
    " - What are the critical difference between various graphs for Class A Share?\n",
    " - Which index best matches Class A share performance closely where Google is not already a part? Explain the reasoning.\n",
    " - Identify key chart patterns for Google Class A shares.\n",
    " - What is cost of revenues, operating expenses and net income for 2020. Do mention the percentage change\n",
    " - What was the effect of Covid in the 2020 financial year?\n",
    " - What are the total revenues for APAC and USA for 2021?\n",
    " - What is deferred income taxes?\n",
    " - How do you compute net income per share?\n",
    " - What drove percentage change in the consolidated revenue and cost of revenue for the year 2021 and was there any effect of Covid?\n",
    " - What is the cause of 41% increase in revenue from 2020 to 2021 and how much is dollar change?\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r65yBb5gR_NG"
   },
   "outputs": [],
   "source": [
    "# Retrieve relevant chunks of text based on the query\n",
    "matching_results_chunks_data = get_similar_text_from_query(\n",
    "    query,\n",
    "    text_metadata_df,\n",
    "    column_name=\"text_embedding_chunk\",\n",
    "    top_n=10,\n",
    "    chunk_text=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wzu5Gf4yR_J4"
   },
   "outputs": [],
   "source": [
    "# Get all relevant images based on user query\n",
    "matching_results_image_fromdescription_data = get_similar_image_from_query(\n",
    "    text_metadata_df,\n",
    "    image_metadata_df,\n",
    "    query=query,\n",
    "    column_name=\"text_embedding_from_image_description\",\n",
    "    image_emb=False,\n",
    "    top_n=10,\n",
    "    embedding_size=1408,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_EEuuLCe6Y5"
   },
   "outputs": [],
   "source": [
    "# combine all the selected relevant text chunks\n",
    "context_text = []\n",
    "for key, value in matching_results_chunks_data.items():\n",
    "    context_text.append(value[\"chunk_text\"])\n",
    "final_context_text = \"\\n\".join(context_text)\n",
    "\n",
    "# combine all the relevant images and their description generated by Gemini\n",
    "context_images = []\n",
    "for key, value in matching_results_image_fromdescription_data.items():\n",
    "    context_images.extend(\n",
    "        [\"Image: \", value[\"image_object\"], \"Caption: \", value[\"image_description\"]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aZuhtJu7fW4n"
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\" Instructions: Compare the images and the text provided as Context: to answer multiple Question:\n",
    "Make sure to think thoroughly before answering the question and put the necessary steps to arrive at the answer in bullet points for easy explainability.\n",
    "If unsure, respond, \"Not enough context to answer\".\n",
    "\n",
    "Context:\n",
    " - Text Context:\n",
    " {final_context_text}\n",
    " - Image Context:\n",
    " {context_images}\n",
    "\n",
    "{query}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Generate Gemini response with streaming output\n",
    "rich_Markdown(\n",
    "    get_gemini_response(\n",
    "        multimodal_model,\n",
    "        model_input=[prompt],\n",
    "        stream=True,\n",
    "        generation_config=GenerationConfig(temperature=1),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IYRLQ47or1I8"
   },
   "outputs": [],
   "source": [
    "print(\"---------------Matched Images------------------\\n\")\n",
    "display_images(\n",
    "    [\n",
    "        matching_results_image_fromdescription_data[0][\"img_path\"],\n",
    "        matching_results_image_fromdescription_data[1][\"img_path\"],\n",
    "        matching_results_image_fromdescription_data[2][\"img_path\"],\n",
    "        matching_results_image_fromdescription_data[3][\"img_path\"],\n",
    "    ],\n",
    "    resize_ratio=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "buwd_gp6HJ5K"
   },
   "outputs": [],
   "source": [
    "# Image citations. You can check how Gemini generated metadata helped in grounding the answer.\n",
    "\n",
    "print_text_to_image_citation(\n",
    "    matching_results_image_fromdescription_data, print_top=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "06vYM4MOHJ1-"
   },
   "outputs": [],
   "source": [
    "# Text citations\n",
    "\n",
    "print_text_to_text_citation(\n",
    "    matching_results_chunks_data,\n",
    "    print_top=False,\n",
    "    chunk_text=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "intro_multimodal_rag.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m126"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
