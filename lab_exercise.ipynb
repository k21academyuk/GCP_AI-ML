{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39d24a6a",
   "metadata": {},
   "source": [
    "# Deploy a BigQuery ML user churn propensity model to Vertex AI for online predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4963f56a",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ce5269-6546-4e54-809b-8fa6e29471dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install google-cloud-aiplatform --user\n",
    "!pip3 install pyarrow==11.0.0 --user\n",
    "!pip3 install --upgrade google-cloud-bigquery --user\n",
    "!pip3 install --upgrade google-cloud-bigquery-storage --user\n",
    "!pip3 install --upgrade google-cloud-storage --user\n",
    "!pip install db-dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ae1c8a",
   "metadata": {},
   "source": [
    "**Restart the kernel and ignore the compatibility errors.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbbab34",
   "metadata": {},
   "source": [
    "### Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbc96b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Retrieve and set PROJECT_ID and REGION environment variables.\n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1bea8f",
   "metadata": {},
   "source": [
    "**Note:** Replace the <code>REGION</code> with the associated region mentioned in the qwiklabs resource panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935a4807",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BQ_LOCATION = 'US'\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1bea9f",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afdade5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud import aiplatform as vertexai\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76acc5de",
   "metadata": {},
   "source": [
    "### Create a GCS bucket for artifact storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc13d5c",
   "metadata": {},
   "source": [
    "Create a globally unique Google Cloud Storage bucket for artifact storage. You will use this bucket to export your BQML model later in the lab and upload it to Vertex AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7682097",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GCS_BUCKET = f\"{PROJECT_ID}-bqmlga4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c003d940",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gsutil mb -l $REGION gs://$GCS_BUCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd34ed14",
   "metadata": {},
   "source": [
    "### Create a BigQuery dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93d1373",
   "metadata": {},
   "source": [
    "Next, create a BigQuery dataset from this notebook using the Python-based \n",
    "\n",
    "This dataset will group your feature views, model, and predictions table together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd775fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BQ_DATASET = f\"{PROJECT_ID}:bqmlga4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53014527",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!bq mk --location={BQ_LOCATION} --dataset {BQ_DATASET}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c8624c",
   "metadata": {},
   "source": [
    "### Initialize the Vertex Python SDK client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af877157",
   "metadata": {},
   "source": [
    "Import the Vertex SDK for Python into your Python environment and initialize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d992f3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vertexai.init(project=PROJECT_ID, location=REGION, staging_bucket=f\"gs://{GCS_BUCKET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dc2862",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA) in BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049d2d38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT \n",
    "    *\n",
    "FROM\n",
    "  `firebase-public-project.analytics_153293282.events_*`\n",
    "    \n",
    "TABLESAMPLE SYSTEM (1 PERCENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d29123",
   "metadata": {},
   "source": [
    "Note: in the cell above, Jupyterlab runs cells starting with `%%bigquery` as SQL queries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0833a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT \n",
    "    COUNT(DISTINCT user_pseudo_id) as count_distinct_users,\n",
    "    COUNT(event_timestamp) as count_events\n",
    "FROM\n",
    "  `firebase-public-project.analytics_153293282.events_*`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764fbeaa",
   "metadata": {},
   "source": [
    "## Dataset preparation in BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0880f4fa",
   "metadata": {},
   "source": [
    "### Defining churn for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab5c7d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "CREATE OR REPLACE VIEW bqmlga4.user_churn AS (\n",
    "  WITH firstlasttouch AS (\n",
    "    SELECT\n",
    "      user_pseudo_id,\n",
    "      MIN(event_timestamp) AS user_first_engagement,\n",
    "      MAX(event_timestamp) AS user_last_engagement\n",
    "    FROM\n",
    "      `firebase-public-project.analytics_153293282.events_*`\n",
    "    WHERE event_name=\"user_engagement\"\n",
    "    GROUP BY\n",
    "      user_pseudo_id\n",
    "\n",
    "  )\n",
    "  \n",
    "SELECT\n",
    "    user_pseudo_id,\n",
    "    user_first_engagement,\n",
    "    user_last_engagement,\n",
    "    EXTRACT(MONTH from TIMESTAMP_MICROS(user_first_engagement)) as month,\n",
    "    EXTRACT(DAYOFYEAR from TIMESTAMP_MICROS(user_first_engagement)) as julianday,\n",
    "    EXTRACT(DAYOFWEEK from TIMESTAMP_MICROS(user_first_engagement)) as dayofweek,\n",
    "\n",
    "    #add 24 hr to user's first touch\n",
    "    (user_first_engagement + 86400000000) AS ts_24hr_after_first_engagement,\n",
    "    \n",
    "    #churned = 1 if last_touch within 24 hr of app installation, else 0\n",
    "    IF (user_last_engagement < (user_first_engagement + 86400000000),\n",
    "    1,\n",
    "    0 ) AS churned,\n",
    "    \n",
    "    #bounced = 1 if last_touch within 10 min, else 0\n",
    "    IF (user_last_engagement <= (user_first_engagement + 600000000),\n",
    "    1,\n",
    "    0 ) AS bounced,\n",
    "  FROM\n",
    "    firstlasttouch\n",
    "  GROUP BY\n",
    "    user_pseudo_id,\n",
    "    user_first_engagement,\n",
    "    user_last_engagement\n",
    "    );\n",
    "\n",
    "SELECT \n",
    "  * \n",
    "FROM \n",
    "  bqmlga4.user_churn \n",
    "LIMIT 100;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b731ce4c",
   "metadata": {},
   "source": [
    "Review how many of the 15k users bounced and returned below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cdaa9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT\n",
    "    bounced,\n",
    "    churned, \n",
    "    COUNT(churned) as count_users\n",
    "FROM\n",
    "    bqmlga4.user_churn\n",
    "GROUP BY \n",
    "  bounced,\n",
    "  churned\n",
    "ORDER BY \n",
    "  bounced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1fc447",
   "metadata": {},
   "source": [
    "For the training data, you will only end up using data where bounced = 0. Based on the 15k users, you can see that 5,557 ( about 41%) users bounced within the first ten minutes of their first engagement with the app. Of the remaining 8,031 users, 1,883 users ( about 23%) churned after 24 hours which you can validate with the query below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ae920e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT\n",
    "    COUNTIF(churned=1)/COUNT(churned) as churn_rate\n",
    "FROM\n",
    "    bqmlga4.user_churn\n",
    "WHERE bounced = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef78f94",
   "metadata": {},
   "source": [
    "### Extract user demographic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd36306f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "CREATE OR REPLACE VIEW bqmlga4.user_demographics AS (\n",
    "\n",
    "  WITH first_values AS (\n",
    "      SELECT\n",
    "          user_pseudo_id,\n",
    "          geo.country as country,\n",
    "          device.operating_system as operating_system,\n",
    "          device.language as language,\n",
    "          ROW_NUMBER() OVER (PARTITION BY user_pseudo_id ORDER BY event_timestamp DESC) AS row_num\n",
    "      FROM `firebase-public-project.analytics_153293282.events_*`\n",
    "      WHERE event_name=\"user_engagement\"\n",
    "      )\n",
    "  SELECT * EXCEPT (row_num)\n",
    "  FROM first_values\n",
    "  WHERE row_num = 1\n",
    "  );\n",
    "\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  bqmlga4.user_demographics\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11abe88b",
   "metadata": {},
   "source": [
    "### Aggregate user behavioral features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9be082c",
   "metadata": {},
   "source": [
    "As a first step, you can explore all the unique events that exist in this dataset, based on event_name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debac29c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT\n",
    "  event_name,\n",
    "  COUNT(event_name) as event_count\n",
    "FROM\n",
    "    `firebase-public-project.analytics_153293282.events_*`\n",
    "GROUP BY \n",
    "  event_name\n",
    "ORDER BY\n",
    "   event_count DESC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6596f7be",
   "metadata": {},
   "source": [
    "For this lab, to predict whether a user will churn or return, you can start by counting the number of times a user engages in the following event types:\n",
    "\n",
    "* user_engagement\n",
    "* level_start_quickplay\n",
    "* level_end_quickplay\n",
    "* level_complete_quickplay\n",
    "* level_reset_quickplay\n",
    "* post_score\n",
    "* spend_virtual_currency\n",
    "* ad_reward\n",
    "* challenge_a_friend\n",
    "* completed_5_levels\n",
    "* use_extra_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60502c0a",
   "metadata": {},
   "source": [
    "In the SQL query below, you will aggregate the behavioral data by calculating the total number of times when each of the above event_names occurred in the data set per user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b016e18d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "CREATE OR REPLACE VIEW bqmlga4.user_behavior AS (\n",
    "WITH\n",
    "  events_first24hr AS (\n",
    "    # Select user data only from first 24 hr of using the app.\n",
    "    SELECT\n",
    "      e.*\n",
    "    FROM\n",
    "      `firebase-public-project.analytics_153293282.events_*` e\n",
    "    JOIN\n",
    "      bqmlga4.user_churn c\n",
    "    ON\n",
    "      e.user_pseudo_id = c.user_pseudo_id\n",
    "    WHERE\n",
    "      e.event_timestamp <= c.ts_24hr_after_first_engagement\n",
    "    )\n",
    "SELECT\n",
    "  user_pseudo_id,\n",
    "  SUM(IF(event_name = 'user_engagement', 1, 0)) AS cnt_user_engagement,\n",
    "  SUM(IF(event_name = 'level_start_quickplay', 1, 0)) AS cnt_level_start_quickplay,\n",
    "  SUM(IF(event_name = 'level_end_quickplay', 1, 0)) AS cnt_level_end_quickplay,\n",
    "  SUM(IF(event_name = 'level_complete_quickplay', 1, 0)) AS cnt_level_complete_quickplay,\n",
    "  SUM(IF(event_name = 'level_reset_quickplay', 1, 0)) AS cnt_level_reset_quickplay,\n",
    "  SUM(IF(event_name = 'post_score', 1, 0)) AS cnt_post_score,\n",
    "  SUM(IF(event_name = 'spend_virtual_currency', 1, 0)) AS cnt_spend_virtual_currency,\n",
    "  SUM(IF(event_name = 'ad_reward', 1, 0)) AS cnt_ad_reward,\n",
    "  SUM(IF(event_name = 'challenge_a_friend', 1, 0)) AS cnt_challenge_a_friend,\n",
    "  SUM(IF(event_name = 'completed_5_levels', 1, 0)) AS cnt_completed_5_levels,\n",
    "  SUM(IF(event_name = 'use_extra_steps', 1, 0)) AS cnt_use_extra_steps,\n",
    "FROM\n",
    "  events_first24hr\n",
    "GROUP BY\n",
    "  user_pseudo_id\n",
    "  );\n",
    "\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  bqmlga4.user_behavior\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77089f30",
   "metadata": {},
   "source": [
    "### Prepare your train/eval/test datasets for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448138e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "CREATE OR REPLACE VIEW bqmlga4.ml_features AS (\n",
    "    \n",
    "  SELECT\n",
    "    dem.user_pseudo_id,\n",
    "    IFNULL(dem.country, \"Unknown\") AS country,\n",
    "    IFNULL(dem.operating_system, \"Unknown\") AS operating_system,\n",
    "    IFNULL(REPLACE(dem.language, \"-\", \"X\"), \"Unknown\") AS language,\n",
    "    IFNULL(beh.cnt_user_engagement, 0) AS cnt_user_engagement,\n",
    "    IFNULL(beh.cnt_level_start_quickplay, 0) AS cnt_level_start_quickplay,\n",
    "    IFNULL(beh.cnt_level_end_quickplay, 0) AS cnt_level_end_quickplay,\n",
    "    IFNULL(beh.cnt_level_complete_quickplay, 0) AS cnt_level_complete_quickplay,\n",
    "    IFNULL(beh.cnt_level_reset_quickplay, 0) AS cnt_level_reset_quickplay,\n",
    "    IFNULL(beh.cnt_post_score, 0) AS cnt_post_score,\n",
    "    IFNULL(beh.cnt_spend_virtual_currency, 0) AS cnt_spend_virtual_currency,\n",
    "    IFNULL(beh.cnt_ad_reward, 0) AS cnt_ad_reward,\n",
    "    IFNULL(beh.cnt_challenge_a_friend, 0) AS cnt_challenge_a_friend,\n",
    "    IFNULL(beh.cnt_completed_5_levels, 0) AS cnt_completed_5_levels,\n",
    "    IFNULL(beh.cnt_use_extra_steps, 0) AS cnt_use_extra_steps,\n",
    "    chu.user_first_engagement,\n",
    "    chu.month,\n",
    "    chu.julianday,\n",
    "    chu.dayofweek,\n",
    "    chu.churned,\n",
    "    # https://towardsdatascience.com/ml-design-pattern-5-repeatable-sampling-c0ccb2889f39\n",
    "    # BQML Hyperparameter tuning requires STRING 3 partition data_split column.\n",
    "    # 80% 'TRAIN' | 10%'EVAL' | 10% 'TEST'    \n",
    "    CASE\n",
    "      WHEN ABS(MOD(FARM_FINGERPRINT(dem.user_pseudo_id), 10)) <= 7\n",
    "        THEN 'TRAIN'\n",
    "      WHEN ABS(MOD(FARM_FINGERPRINT(dem.user_pseudo_id), 10)) = 8\n",
    "        THEN 'EVAL'\n",
    "      WHEN ABS(MOD(FARM_FINGERPRINT(dem.user_pseudo_id), 10)) = 9\n",
    "        THEN 'TEST'    \n",
    "          ELSE '' END AS data_split\n",
    "  FROM\n",
    "    bqmlga4.user_churn chu\n",
    "  LEFT OUTER JOIN\n",
    "    bqmlga4.user_demographics dem\n",
    "  ON \n",
    "    chu.user_pseudo_id = dem.user_pseudo_id\n",
    "  LEFT OUTER JOIN \n",
    "    bqmlga4.user_behavior beh\n",
    "  ON\n",
    "    chu.user_pseudo_id = beh.user_pseudo_id\n",
    "  WHERE chu.bounced = 0\n",
    "  );\n",
    "\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  bqmlga4.ml_features\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc4f5f9",
   "metadata": {},
   "source": [
    "### Validate feature splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af097e0",
   "metadata": {},
   "source": [
    "Run the query below to validate the number of examples in each data partition for the 80% train |10% eval |10% test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb419c16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT\n",
    "  data_split,\n",
    "  COUNT(*) AS n_examples\n",
    "FROM bqmlga4.ml_features\n",
    "GROUP BY data_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2767dae",
   "metadata": {},
   "source": [
    "## Train and tune a BQML XGBoost propensity model to predict customer churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f84f45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_NAME=\"churn_xgb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4bbf26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "CREATE OR REPLACE MODEL bqmlga4.churn_xgb\n",
    "\n",
    "OPTIONS(\n",
    "  MODEL_TYPE=\"BOOSTED_TREE_CLASSIFIER\",\n",
    "  # Declare label column.\n",
    "  INPUT_LABEL_COLS=[\"churned\"],\n",
    "  # Specify custom data splitting using the `data_split` column.\n",
    "  DATA_SPLIT_METHOD=\"CUSTOM\",\n",
    "  DATA_SPLIT_COL=\"data_split\",\n",
    "  # Enable Vertex Explainable AI aggregated feature attributions.\n",
    "  ENABLE_GLOBAL_EXPLAIN=True,\n",
    "  # Hyperparameter tuning arguments.\n",
    "  num_trials=8,\n",
    "  max_parallel_trials=4,\n",
    "  HPARAM_TUNING_OBJECTIVES=[\"roc_auc\"],\n",
    "  EARLY_STOP=True,\n",
    "  # Hyperpameter search space.\n",
    "  LEARN_RATE=HPARAM_RANGE(0.01, 0.1),\n",
    "  MAX_TREE_DEPTH=HPARAM_CANDIDATES([5,6])\n",
    ") AS\n",
    "\n",
    "SELECT\n",
    "  * EXCEPT(user_pseudo_id)\n",
    "FROM\n",
    "  bqmlga4.ml_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2beffd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT *\n",
    "FROM\n",
    "  ML.TRIAL_INFO(MODEL `bqmlga4.churn_xgb`);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb9dc3a",
   "metadata": {},
   "source": [
    "## Evaluate BQML XGBoost model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb9896b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  ML.EVALUATE(MODEL bqmlga4.churn_xgb)\n",
    "WHERE trial_id=1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15b2e45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT\n",
    "  expected_label,\n",
    "  _0 AS predicted_0,\n",
    "  _1 AS predicted_1\n",
    "FROM\n",
    "  ML.CONFUSION_MATRIX(MODEL bqmlga4.churn_xgb)\n",
    "WHERE trial_id=1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f9e493",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery df_roc --project $PROJECT_ID\n",
    "\n",
    "SELECT * FROM ML.ROC_CURVE(MODEL bqmlga4.churn_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da715945",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_roc.plot(x=\"false_positive_rate\", y=\"recall\", title=\"AUC-ROC curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e51a9bc",
   "metadata": {},
   "source": [
    "## Inspect global feature attributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b505dae3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  ML.GLOBAL_EXPLAIN(MODEL bqmlga4.churn_xgb)\n",
    "ORDER BY\n",
    "  attribution DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b471e6ee",
   "metadata": {},
   "source": [
    "## Generate batch predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b117c407",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  ML.PREDICT(MODEL bqmlga4.churn_xgb,\n",
    "  (SELECT * FROM bqmlga4.ml_features WHERE data_split = \"TEST\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dac74c",
   "metadata": {},
   "source": [
    "The following query returns the probability that the user will return after 24 hrs. The higher the probability and closer it is to 1, the more likely the user is predicted to churn, and the closer it is to 0, the more likely the user is predicted to return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7411bff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "CREATE OR REPLACE TABLE bqmlga4.churn_predictions AS (\n",
    "SELECT\n",
    "  user_pseudo_id,\n",
    "  churned,\n",
    "  predicted_churned,\n",
    "  predicted_churned_probs[OFFSET(0)].prob as probability_churned\n",
    "FROM\n",
    "  ML.PREDICT(MODEL bqmlga4.churn_xgb,\n",
    "  (SELECT * FROM bqmlga4.ml_features))\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c037410",
   "metadata": {},
   "source": [
    "## Export a BQML model to Vertex AI for online predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6593da8c",
   "metadata": {},
   "source": [
    "### Export BQML model to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f50a47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BQ_MODEL = f\"{BQ_DATASET}.{MODEL_NAME}\"\n",
    "BQ_MODEL_EXPORT_DIR = f\"gs://{GCS_BUCKET}/{MODEL_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee61430a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!bq --location=$BQ_LOCATION extract \\\n",
    "--destination_format ML_XGBOOST_BOOSTER \\\n",
    "--model $BQ_MODEL \\\n",
    "$BQ_MODEL_EXPORT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f336458",
   "metadata": {},
   "source": [
    "Navigate to [Google Cloud Storage](https://pantheon.corp.google.com/storage) in Google Cloud Console to `\"gs://{GCS_BUCKET}/{MODEL_NAME}\"`. Validate that you see your exported model assets in the below format:\n",
    "\n",
    "```\n",
    "|--/{GCS_BUCKET}/{MODEL_NAME}/\n",
    "   |--/assets/                       # Contains preprocessing code.  \n",
    "      |--0_categorical_label.txt     # Contains country vocabulary.\n",
    "      |--1_categorical_label.txt     # Contains operating_system vocabulary.\n",
    "      |--2_categorical_label.txt     # Contains language vocabulary.\n",
    "      |--model_metadata.json         # contains model feature and label mappings.\n",
    "   |--main.py                        # Can be called for local training runs.\n",
    "   |--model.bst                      # XGBoost saved model format.\n",
    "   |--xgboost_predictor-0.1.tar.gz   # Compress XGBoost model with prediction function. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71122b86",
   "metadata": {},
   "source": [
    "### Upload BQML model to Vertex AI from GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86cd67e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMAGE_URI='us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-4:latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3278567",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = vertexai.Model.upload(\n",
    "    display_name=MODEL_NAME,\n",
    "    artifact_uri=BQ_MODEL_EXPORT_DIR,\n",
    "    serving_container_image_uri=IMAGE_URI,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0874197c",
   "metadata": {},
   "source": [
    "### Deploy a Vertex `Endpoint` for online predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5368fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint = model.deploy(\n",
    "    traffic_split={\"0\": 100},\n",
    "    machine_type=\"e2-standard-2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8448a1",
   "metadata": {},
   "source": [
    "### Query model for online predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b647538",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CATEGORICAL_FEATURES = ['country',\n",
    "                        'operating_system',\n",
    "                        'language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bb0e82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350c5727",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _build_cat_feature_encoders(cat_feature_list, gcs_bucket, model_name, na_value='Unknown'):\n",
    "    \"\"\"Build categorical feature encoders for mapping text to integers for XGBoost inference. \n",
    "    Args:\n",
    "      cat_feature_list (list): List of string feature names.\n",
    "      gcs_bucket (str): A string path to your Google Cloud Storage bucket.\n",
    "      model_name (str): A string model directory in GCS where your BQML model was exported to.\n",
    "      na_value (str): default is 'Unknown'. String value to replace any vocab NaN values prior to encoding.\n",
    "    Returns:\n",
    "      feature_encoders (dict): A dictionary containing OrdinalEncoder objects for integerizing \n",
    "        categorical features that has the format [feature] = feature encoder.\n",
    "    \"\"\"\n",
    "    \n",
    "    feature_encoders = {}\n",
    "    \n",
    "    for idx, feature in enumerate(cat_feature_list):\n",
    "        feature_encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "        feature_vocab_file = f\"gs://{gcs_bucket}/{model_name}/assets/{idx}_categorical_label.txt\"\n",
    "        feature_vocab_df = pd.read_csv(feature_vocab_file, delimiter = \"\\t\", header=None).fillna(na_value)\n",
    "        feature_encoder.fit(feature_vocab_df.values)\n",
    "        feature_encoders[feature] = feature_encoder\n",
    "    \n",
    "    return feature_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809875a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_xgboost(instances, cat_feature_list, feature_encoders):\n",
    "    \"\"\"Transform instances to numerical values for inference.\n",
    "    Args:\n",
    "      instances (list[dict]): A list of feature dictionaries with the format feature: value. \n",
    "      cat_feature_list (list): A list of string feature names.\n",
    "      feature_encoders (dict): A dictionary with the format feature: feature_encoder.\n",
    "    Returns:\n",
    "      transformed_instances (list[list]): A list of lists containing numerical feature values needed\n",
    "        for Vertex XGBoost inference.\n",
    "    \"\"\"\n",
    "    transformed_instances = []\n",
    "    \n",
    "    for instance in instances:\n",
    "        for feature in cat_feature_list:\n",
    "            feature_int = feature_encoders[feature].transform([[instance[feature]]]).item()\n",
    "            instance[feature] = feature_int\n",
    "            instance_list = list(instance.values())\n",
    "        transformed_instances.append(instance_list)\n",
    "\n",
    "    return transformed_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae41101",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build a dictionary of ordinal categorical feature encoders.\n",
    "feature_encoders = _build_cat_feature_encoders(CATEGORICAL_FEATURES, GCS_BUCKET, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201f0aa9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery test_df --project $PROJECT_ID \n",
    "\n",
    "SELECT* EXCEPT (user_pseudo_id, churned, data_split)\n",
    "FROM bqmlga4.ml_features\n",
    "WHERE data_split=\"TEST\"\n",
    "LIMIT 3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d397bc03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert dataframe records to feature dictionaries for preprocessing by feature name.\n",
    "test_instances = test_df.astype(str).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19ade61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply preprocessing to transform categorical features and return numerical instances for prediction.\n",
    "transformed_test_instances = preprocess_xgboost(test_instances, CATEGORICAL_FEATURES, feature_encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873c0db2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate predictions from model deployed to Vertex AI Endpoint.\n",
    "predictions = endpoint.predict(instances=transformed_test_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a08430",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx, prediction in enumerate(predictions.predictions):\n",
    "    # Class labels [1,0] retrieved from model_metadata.json in GCS model dir.\n",
    "    # BQML binary classification default is 0.5 with above \"Churn\" and below \"Not Churn\".\n",
    "    is_churned = \"Churn\" if prediction[0] >= 0.5 else \"Not Churn\"\n",
    "    print(f\"Prediction: Customer {idx} - {is_churned} {prediction}\")\n",
    "    print(test_df.iloc[idx].astype(str).to_json() + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-15.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-15:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
